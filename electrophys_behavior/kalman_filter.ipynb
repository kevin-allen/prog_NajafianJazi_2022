{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eed1d861-8a5c-4288-8753-3620d8ea7bf4",
   "metadata": {},
   "source": [
    "# Kalman filter of position data\n",
    "\n",
    "We want to remove as much noise from the position tracking data. We will apply the filter to reported x and y position of the mouse.\n",
    "\n",
    "A few preprocessing steps are applied to the position data before applying the Kalman filter to remove values that were clearly wrong.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9177f37-27c6-417a-a3da-ee2d6c104048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project name: autopi_ca1\n",
      "dataPath: /adata/projects/autopi_ca1\n",
      "dlcModelPath: /adata/models\n",
      "Reading /adata/projects/autopi_ca1/sessionList\n",
      "We have 40 testing sessions in the list\n",
      "See myProject and sSesList objects\n",
      "Loading Animal_pose and Spike_train, sSes.ap and sSes.cg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:33<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ses.trial_table_simple as ses.trials\n",
      "Create condition intervals in ses.intervalDict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%run setup_project.py\n",
    "prepareSessionsForSpatialAnalysisProject(sSesList,myProject.sessionList)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3cd004-8ff2-439a-ae4a-c7c827bc41e2",
   "metadata": {},
   "source": [
    "## Preprocessing steps\n",
    "\n",
    "\n",
    "These functions apply some corrections to the raw data (remove clear jumps, correct for 180 flip of head direction, and use offline tracking if available to fill gaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdc04d62-64fc-4632-bbe7-8ec9fdbf2880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from spikeA.Session import Session\n",
    "\n",
    "def remove_speed_jumps(df, time, px_per_cm , max_speed=200):\n",
    "    \"\"\"\n",
    "    set x,y,hd to np.nan when speed is above a threshod\n",
    "    \n",
    "    Argument\n",
    "    df: DataFrame with x, y , hd data\n",
    "    time: time of each frame in DataFrame, in seconds\n",
    "    px_per_cm: pixels per cm\n",
    "    \"\"\"\n",
    "\n",
    "    dt = np.diff(time,append = np.nan)\n",
    "    dx = np.diff(df.x,append = np.nan)\n",
    "    dy = np.diff(df.y,append = np.nan)\n",
    "    speed = (np.sqrt(dx**2+dy**2)/dt)/px_per_cm\n",
    "    df[\"speed\"] = speed\n",
    "    \n",
    "    speed_issues = speed > max_speed\n",
    "    print(\"Number of speed issues: {}\".format(np.sum(speed_issues)))\n",
    "    \n",
    "    df.x[speed_issues] = np.nan\n",
    "    df.y[speed_issues] = np.nan\n",
    "    df.hd[speed_issues] = np.nan\n",
    "    df.speed[speed_issues] = np.nan\n",
    "    \n",
    "    return df\n",
    "\n",
    "def correct_head_direction_180_flip(df, time, px_per_cm , min_speed=10, max_angle=np.pi/1.2):\n",
    "    \"\"\"\n",
    "    Rotate by pi the head-direction if the difference between heading and head-direction is more than max_angle when the animal is moving above a speed threshold. \n",
    "    \n",
    "    Mice do not move forward with their head pointing backward. If we get this in our data, it is likely due to a swap in the 2 LEDs \n",
    "    \n",
    "    Argument\n",
    "    df: DataFrame with x, y , hd data\n",
    "    time: time of each frame in DataFrame\n",
    "    px_per_cm: pixels per cm\n",
    "    min_speed: minimal speed at which heading and head-direction should be compared\n",
    "    max_angle: max angle between heading and head-direction that is considered valid.\n",
    "    \"\"\"\n",
    "        \n",
    "    dt = np.diff(time,append = np.nan)\n",
    "    dx = np.diff(df.x,append = np.nan)\n",
    "    dy = np.diff(df.y,append = np.nan)\n",
    "    speed = (np.sqrt(dx**2+dy**2)/dt)/px_per_cm\n",
    "    df[\"speed\"] = speed\n",
    "    df[\"heading\"] = np.arctan2(dy,dx)\n",
    "    \n",
    "    # angle between 2 vector is the acos of the dot product\n",
    "    delta_angle = np.arccos( np.cos(df.hd)*np.cos(df.heading)+np.sin(df.hd)*np.sin(df.heading) )\n",
    "    \n",
    "    swap_indices = np.logical_and(df.speed>min_speed,delta_angle>max_angle)\n",
    "    \n",
    "    df.hd[swap_indices] = np.arctan2(np.sin(df.hd[swap_indices]+np.pi),np.cos(df.hd[swap_indices]+np.pi))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def merge_online_offline_tracking(df,df1,prob=0.995):\n",
    "    \"\"\"\n",
    "    Function to fill missing x,y,hd from online tracking with dlc model output.\n",
    "    \n",
    "    This only works if we have done offline tracking. \n",
    "    \n",
    "    We fill only when dlc was pretty sure about detecting the mouse (data above prob threshold)\n",
    "    \n",
    "    Arguments:\n",
    "    df : online tracking data (positrack2 file)\n",
    "    df1: offline tracking data (offline dlc model output)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    i1 = np.isnan(df.x) # df is nan\n",
    "    print(\"Proportion of nan in online tracking: {:.3f}\".format(np.sum(np.isnan(df.x)/df.x.shape[0])))\n",
    "    \n",
    "    if df1 is None:\n",
    "        print(\"No valid df1\")\n",
    "        return\n",
    "    \n",
    "    i2 = np.logical_and(df1.LedLeft_p>prob, df1.LedRight_p>prob) # we have good dlc confidence\n",
    "    i = np.logical_and(i1,i2)\n",
    "    \n",
    "    print(\"Proportion of nan in offline tracking: {:.3f}\".format(np.sum(np.isnan(df1.x)/df1.x.shape[0])))\n",
    "                                                                 \n",
    "    print(\"Number of np.nan filling using dlc: {}\".format(np.sum(i)))\n",
    "    df.x[i] = df1.x[i]\n",
    "    df.y[i] = df1.y[i]\n",
    "    df.hd[i] = df1.hd[i]\n",
    "                                                                 \n",
    "    print(\"Proportion of nan after merging: {:.3f}\".format(np.sum(np.isnan(df.x)/df.x.shape[0])))\n",
    "                                                                 \n",
    "    return df\n",
    "\n",
    "def post_processing_positrack2_file(sSes, trialName, extension=\"positrack2\",alt_extension=\"offline.positrack2\", output_extension=\"positrack2_post\"):\n",
    "    \"\"\"\n",
    "    Function to apply post processing to the position tracking data\n",
    "    \n",
    "    Work on a sinble positrack2 file\n",
    "    \n",
    "    sSes: spikeA session\n",
    "    trial_name: name of a single trial\n",
    "    extension: extension of the positrack2 file\n",
    "    alt_extension: name of the extension for alternative position data file (see dlc_on_positrack2_videos)\n",
    "    \n",
    "    \"\"\"\n",
    "    if sSes is None:\n",
    "        raise TypeError(\"Please provide a session object with the ses argument\")\n",
    "    \n",
    "    if not (issubclass(type(sSes),Session) or isinstance(sSes,Session)): \n",
    "        raise TypeError(\"ses should be a subclass of the Session class\")\n",
    "    \n",
    "    print(\"***************\")\n",
    "    print(trialName)\n",
    "    posiFn = sSes.path+\"/\"+trialName+\".\"+extension\n",
    "        \n",
    "    positrack_file = Path(posiFn)\n",
    "    if not positrack_file.exists() :\n",
    "        raise OSError(\"positrack file {} missing\".format(positrack_file_name))\n",
    "    print(\"Loading \",positrack_file)\n",
    "    df = pd.read_csv(positrack_file)\n",
    "    print(\"positrack2 file with {} lines\".format(df.shape[0]))\n",
    "    print(\"Proportion of nan in original positrack2 file: {:.3f}\".format(np.sum(np.isnan(df.x)/df.x.shape[0])))\n",
    "    \n",
    "    \n",
    "    \n",
    "    posiAltFn = sSes.path+\"/\"+trialName+\".\"+alt_extension\n",
    "    positrack_alt_file = Path(posiAltFn)\n",
    "    if positrack_alt_file.exists() :\n",
    "        print(\"Loading \",positrack_alt_file)\n",
    "        df1 = pd.read_csv(positrack_alt_file)\n",
    "        print(positrack_alt_file,\"has {} lines\".format(df1.shape[0]))\n",
    "        if df1.shape[0] ==0:\n",
    "            df1= None\n",
    "    else:\n",
    "        print(\"No \",positrack_alt_file)\n",
    "        df1 = None\n",
    "    \n",
    "    if df1 is None:\n",
    "        print(\"No offline tracking to improve on online tracking\")\n",
    "    \n",
    "    if df1 is not None:\n",
    "        if (df.shape[0] != df1.shape[0]):\n",
    "            raise ValueError(\"the two position data file do not have the same length\")\n",
    "    \n",
    "    \n",
    "\n",
    "    # if there are subsequent frames with the same acquisition time, set to np.nan as it will confuse the gh filter\n",
    "    dt=np.diff(df.acq_time_source_2,append=np.nan)\n",
    "    indices = dt==0\n",
    "    print(\"Number of delta time == 0: {}\".format(np.sum(indices)))\n",
    "    df.x[indices] = np.nan\n",
    "    df.y[indices] = np.nan\n",
    "    df.hd[indices] = np.nan\n",
    "\n",
    "\n",
    "    if df1 is not None:\n",
    "        df1.x[indices] = np.nan\n",
    "        df1.y[indices] = np.nan\n",
    "        df1.hd[indices] = np.nan\n",
    "\n",
    "    # we want the head-direction data in radians\n",
    "    if (np.nanmax(df.hd)>np.pi): # if in degrees\n",
    "        df.hd = df.hd/360*np.pi*2\n",
    "        df.hd = np.arctan2(np.sin(df.hd),np.cos(df.hd))\n",
    "    if df1 is not None:\n",
    "        if (np.nanmax(df1.hd)>np.pi): # if in degrees\n",
    "            df1.hd = df1.hd/360*np.pi*2\n",
    "            df1.hd = np.arctan2(np.sin(df1.hd),np.cos(df1.hd))\n",
    "    \n",
    "    \n",
    "    # remove speed jumps\n",
    "    df = remove_speed_jumps(df = df,\n",
    "                        time = df.acq_time_source_2,\n",
    "                        px_per_cm = sSes.px_per_cm)\n",
    "    if df1 is not None:\n",
    "        df1 = remove_speed_jumps(df = df1,\n",
    "                            time = df.acq_time_source_2,\n",
    "                            px_per_cm = sSes.px_per_cm)\n",
    "\n",
    "    # remove hd flips\n",
    "    df = correct_head_direction_180_flip(df,df.acq_time_source_0,sSes.px_per_cm)\n",
    "    if df1 is not None:\n",
    "        df1 = correct_head_direction_180_flip(df1,df.acq_time_source_0,sSes.px_per_cm)\n",
    "\n",
    "        \n",
    "    # use the dlc model output to fill in the np.nan from online tracking\n",
    "    if df1 is not None:                        \n",
    "        df = merge_online_offline_tracking(df,df1)\n",
    "    \n",
    "    \n",
    "    ## saving \"positrack2_post\" file\n",
    "    newDf = df.copy()\n",
    "    \n",
    "    outPosiFn = sSes.path+\"/\"+trialName+\".\"+ output_extension    \n",
    "    newDf.to_csv(outPosiFn,index=False)\n",
    "    print(\"Saving output to \",outPosiFn)\n",
    "    \n",
    "    return\n",
    "\n",
    "def post_processing_positrack_file(sSes, trialName, extension=\"positrack\", output_extension=\"positrack_post\"):\n",
    "    \"\"\"\n",
    "    Function to apply post processing to the position tracking data\n",
    "    \n",
    "    Work on a single positrack file\n",
    "    \n",
    "    sSes: spikeA session\n",
    "    trial_name: name of a single trial\n",
    "    extension: extension of the positrack file\n",
    "    output_extension: name of the extension for the processed data\n",
    "    \n",
    "    \"\"\"\n",
    "    if sSes is None:\n",
    "        raise TypeError(\"Please provide a session object with the ses argument\")\n",
    "    \n",
    "    if not (issubclass(type(sSes),Session) or isinstance(sSes,Session)): \n",
    "        raise TypeError(\"ses should be a subclass of the Session class\")\n",
    "    \n",
    "    print(\"***************\")\n",
    "    print(trialName)\n",
    "    posiFn = sSes.path+\"/\"+trialName+\".\"+extension\n",
    "        \n",
    "    positrack_file = Path(posiFn)\n",
    "    if not positrack_file.exists() :\n",
    "        raise OSError(\"positrack file {} missing\".format(positrack_file_name))\n",
    "    print(\"Loading \",positrack_file)\n",
    "    df = pd.read_csv(positrack_file,sep=\" \")\n",
    "    print(\"positrack file with {} lines\".format(df.shape[0]))\n",
    "   \n",
    "    \n",
    "    # set invalid to np.nan\n",
    "    df.x[df.x==-1.0] = np.nan\n",
    "    df.y[df.y==-1.0] = np.nan\n",
    "    df.hd[np.isnan(df.x)] = np.nan\n",
    "    \n",
    "    if (np.nanmax(df.hd)>np.pi): # if in degrees\n",
    "        df.hd = df.hd/360*np.pi*2\n",
    "        df.hd = np.arctan2(np.sin(df.hd),np.cos(df.hd))\n",
    "        \n",
    "        \n",
    "    print(\"Proportion of nan in original positrack2 file: {:.3f}\".format(np.sum(np.isnan(df.x)/df.x.shape[0])))\n",
    "    \n",
    "    # remove speed jumps\n",
    "    df = remove_speed_jumps(df = df,\n",
    "                        time = df.capTime/1000, # in seconds\n",
    "                        px_per_cm = sSes.px_per_cm)\n",
    "    \n",
    "    outPosiFn = sSes.path+\"/\"+trialName+\".\"+ output_extension    \n",
    "    df.to_csv(outPosiFn,index=False)\n",
    "    print(\"Saving output to \",outPosiFn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68ed52c-1994-4948-b12e-c40fc84767a7",
   "metadata": {},
   "source": [
    "Start with sessions from positrack2. We have the video that we can use to improve tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "de148b4b-67b1-4952-969e-f6cc148ada2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positrack2 sessions:  16\n",
      "Number of positrack sessions:  28\n"
     ]
    }
   ],
   "source": [
    "positrack2_sessions = [ ses for ses in sSesList if ses.ap.positrack_type()==\"positrack2\"]\n",
    "print(\"Number of positrack2 sessions: \", len(positrack2_sessions))\n",
    "\n",
    "positrack_sessions = [ ses for ses in sSesList if ses.ap.positrack_type()==\"positrack\"]\n",
    "print(\"Number of positrack sessions: \", len(positrack_sessions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feedbf7-a099-4012-a873-d371c7d30ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sSes in enumerate(positrack_sessions):\n",
    "    print(i, sSes.name)\n",
    "    for t in sSes.trial_names:\n",
    "        post_processing_positrack_file(sSes,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0119dc87-84cd-434d-85b6-e030ab0152c5",
   "metadata": {},
   "source": [
    "Run the pre-processing steps on the positrack2 sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a104c8a8-9371-4bc9-9f97-29638e967854",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sSes in enumerate(positrack2_sessions):\n",
    "    print(i, sSes.name)\n",
    "    for t in sSes.trial_names:\n",
    "        post_processing_positrack2_file(sSes,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f804c08f-4352-412e-9438-1530b11a1e3d",
   "metadata": {},
   "source": [
    "## Kalman filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e624a4fb-8e25-4ab5-bdc8-1f4c79b3200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_vel_filter(x, P, R, Q=0., dt=1.0):\n",
    "    \"\"\"\n",
    "    Returns a KalmanFilter which implements a constant velocity model for a state [x,y,dx,dy].T\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    kf = KalmanFilter(dim_x=4, dim_z=2)\n",
    "    \n",
    "    # initialization of state\n",
    "    kf.x = np.array([x[0], x[1], x[2], x[3]]) # location x, location y, velocity x and velocity y\n",
    "    \n",
    "    # state transition matrix\n",
    "    kf.F = np.array([[1., 0 , dt, 0], # location x * 1 + velocity x * dt\n",
    "                     [0., 1 , 0, dt], # location y * 1 + velocity y * dt\n",
    "                     [0., 0 , 1., 0], # velocity x\n",
    "                     [0., 0 , 0., 1.]]) # velocity y \n",
    "    \n",
    "    \n",
    "\n",
    "    kf.H = np.array([[1., 0, 0, 0],\n",
    "                     [0., 1., 0, 0]])    # Measurement function\n",
    "    kf.R *= R                     # measurement uncertainty\n",
    "    if np.isscalar(P):\n",
    "        kf.P *= P                 # covariance matrix \n",
    "    else:\n",
    "        kf.P[:] = P               # [:] makes deep copy\n",
    "    if np.isscalar(Q):\n",
    "        kf.Q = Q_discrete_white_noise(dim=2, dt=dt, var=Q, block_size = 2, order_by_dim=False)\n",
    "    else:\n",
    "        kf.Q[:] = Q\n",
    "    return kf\n",
    "\n",
    "def run(x0=(400.,400.,0.,0.), P=200, R=0, Q=0, dt=1.0, zs=None,maxConsicutiveInvalids=15):\n",
    "    \"\"\"\n",
    "    Process one data point with the Kalman filter\n",
    "    \n",
    "    This filter assumes that dt is constant.\n",
    "    \n",
    "    Arguments\n",
    "    x0: starting state of the filter\n",
    "    P: \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # create the Kalman filter\n",
    "    kf = pos_vel_filter(x0, R=R, P=P, Q=Q, dt=dt)  \n",
    "    \n",
    "    consecutiveInvalids = 0\n",
    "    # run the kalman filter and store the results\n",
    "    xs, cov = [], []\n",
    "    for z in zs:\n",
    "        if ~np.isnan(z[0]):            \n",
    "            consecutiveInvalids=0\n",
    "            kf.predict()\n",
    "            kf.update(z)\n",
    "            xs.append(kf.x)\n",
    "            cov.append(kf.P)\n",
    "        else:\n",
    "            #print(\"dealing with nan\")\n",
    "            consecutiveInvalids += 1\n",
    "            if consecutiveInvalids < maxConsicutiveInvalids:\n",
    "                kf.predict()\n",
    "                xs.append(kf.x)\n",
    "                cov.append(kf.P)\n",
    "            else: # don't predict, set to invalid\n",
    "                xs.append(np.array([np.nan,np.nan,np.nan,np.nan]))\n",
    "                cov.append(kf.P)\n",
    "            \n",
    "    xs, cov = np.array(xs), np.array(cov)\n",
    "    return xs, cov\n",
    "def filter_positrack_file(sSes, trialName,input_extension=\"positrack2_post\", output_extension=\"positrack2_kf\",with_plot=True):\n",
    "    \n",
    "    posiFn = sSes.path+\"/\"+trialName+\".\"+ input_extension\n",
    "    print(posiFn)\n",
    "    df = pd.read_csv(posiFn)\n",
    "    print(input_extension, \"file with {} lines\".format(df.shape[0]))\n",
    "    print(\"Proportion of nan in original positrack2 file: {:.3f}\".format(np.sum(np.isnan(df.x)/df.x.shape[0])))\n",
    "    \n",
    "    # prepare input data for filter\n",
    "    zsx = df.x.to_numpy()\n",
    "    zsy = df.y.to_numpy()\n",
    "    zs = np.stack([zsx,zsy]).T\n",
    "    \n",
    "    \n",
    "    # plot input data\n",
    "    if with_plot:\n",
    "        fig, axs = plt.subplots(1,3,figsize=(17,4))\n",
    "        axs[0].plot(zs[:,0])\n",
    "        axs[1].plot(zs[:,1])\n",
    "        axs[2].plot(zs[:,0],zs[:,1])\n",
    "    \n",
    "    # get valid position to use as starting position\n",
    "    zsValid=zs[~np.isnan(zs[:,0]),:]\n",
    "    \n",
    "    if input_extension==\"positrack2_post\":\n",
    "        dt=df.acq_time_source_2.diff().median()\n",
    "    elif input_extension==\"positrack_post\":\n",
    "        dt = df.capTime.diff().median()/1000\n",
    "    # apply the filter\n",
    "    Ms, Ps = run(x0=(zsValid[0,0],zsValid[0,1],0,0),R=0.5, Q=1500, P=200,zs=zs,dt=dt)\n",
    "\n",
    "    print(\"Proportion of nan after Kalmin filter: {:.3f}\".format(np.sum(np.isnan(Ms[:,0])/Ms.shape[0])))\n",
    "\n",
    "    \n",
    "    \n",
    "    # remove any position that would be out of range of the original data\n",
    "    toInvalidx = np.logical_or(Ms[:,0]<df.x.min(),Ms[:,0]>df.x.max())\n",
    "    toInvalidy = np.logical_or(Ms[:,1]<df.y.min(),Ms[:,1]>df.y.max())\n",
    "    toInvalid = np.logical_or(toInvalidx,toInvalidy)\n",
    "    print(\"out of range: {}\".format(np.sum(toInvalid)))\n",
    "    Ms[toInvalid,:] = np.nan\n",
    "    \n",
    "    \n",
    "    print(\"Proportion of nan: {:.3f}\".format(np.sum(np.isnan(Ms[:,0])/Ms.shape[0])))\n",
    "\n",
    "    \n",
    "    # replace original position data with filtered data\n",
    "    df.x = Ms[:,0]\n",
    "    df.y = Ms[:,1]\n",
    "    \n",
    "    # save the new file\n",
    "    posiFn = sSes.path+\"/\"+trialName+\".\"+ output_extension\n",
    "    df.to_csv(posiFn,index=False)\n",
    "    print(\"Saving output to\",posiFn)\n",
    "    \n",
    "    \n",
    "    if with_plot:\n",
    "        maxX = 20000\n",
    "        fig,axs = plt.subplots(2,1,figsize=(30,20))\n",
    "        width = 1\n",
    "        for i in range(2):\n",
    "            axs[i].scatter(range(len(zs[:,i])),zs[:,i],zorder=1,c=\"red\")\n",
    "            axs[i].plot(Ms[:,i],zorder=0,c=\"black\",lw=width)\n",
    "            axs[i].set_xlim(0,maxX)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.plot(zs[:,0],zs[:,1],zorder=1,c=\"red\",lw=width)\n",
    "        plt.plot(Ms[:,0],Ms[:,1],zorder=0,c=\"black\",lw=width)\n",
    "        \n",
    "        plt.show()\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.plot(Ms[:,0],Ms[:,1],zorder=0,c=\"black\",lw=width)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025c5d27-799d-4f1b-a6fa-145dc31492ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sSes in positrack_sessions:\n",
    "#sSes = positrack_sessions[-1]\n",
    "    for trialName in sSes.trial_names:\n",
    "#trialName= sSes.trial_names[4]\n",
    "        filter_positrack_file(sSes,trialName,with_plot=False,input_extension=\"positrack_post\", output_extension=\"positrack_kf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c746d4-57ba-4723-ab18-d89f68db1536",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_extension=\"positrack2_post\"\n",
    "for sSes in positrack2_sessions:\n",
    "#sSes = positrack2_sessions[-1]\n",
    "    for trialName in sSes.trial_names:\n",
    "        #trialName= sSes.trial_names[4]\n",
    "        filter_positrack_file(sSes,trialName,with_plot=False,input_extension=\"positrack2_post\", output_extension=\"positrack2_kf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a67911-9912-470a-bc83-98423dbd93cf",
   "metadata": {},
   "source": [
    "In each session directory, there are files with extension `positrack_kf` or `positrack2_kf` with the filtered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f069b374-e638-4618-b318-d129730b78dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DEEPLABCUT] *",
   "language": "python",
   "name": "conda-env-DEEPLABCUT-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
