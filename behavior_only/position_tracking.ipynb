{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Position tracking\n",
    "\n",
    "The classes for object (arena, bridge, mouse lever) detections are in the autopipy package.\n",
    "\n",
    "There are a few steps in this procedure to go from the raw video of the arena to the position of the animal. \n",
    "\n",
    "Steps with the `arena_top.avi` file\n",
    "\n",
    "* Detect the bridge and arena in arena_top.avi\n",
    "* Crop the arena_top.avi to 480x480\n",
    "\n",
    "Steps with the cropped video\n",
    "\n",
    "* Detect arena in cropped video\n",
    "* Detect bridge in cropped video\n",
    "* Detect the mouse and lever in cropped video\n",
    "\n",
    "There is a jupyter notebook in `autopi_analysis/kevin/autopipy_dev_notebooks` in which all the steps for a single session are performed separately. This is a good place to go if you have problems running the analysis on one session.\n",
    "\n",
    "Below is the code to run the analysis on several sessions. \n",
    "\n",
    "It takes approximately **30 minutes per session** with a decent GPU. You can of course run different sessions on different GPU to speed up the process.\n",
    "\n",
    "You will need to run this code from a DLC-GPU virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"DLClight\"]=\"True\" # if you don't need dlb gui\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import autopipy\n",
    "import importlib\n",
    "from autopipy.project import Project\n",
    "from autopipy.video_utilities import positionTrackingFromArenaTopVideo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get our project with the list of sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project name: autopi_behavior_2021\n",
      "dataPath: /adata/projects/autopi_behavior_2021\n",
      "dlcModelPath: /adata/models\n",
      "Reading /adata/projects/autopi_behavior_2021/memory_sessions\n",
      "We have 10 recording sessions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sessionName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mn9686-12052021-1702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TYY5622-12052021-1805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TYY5630-12052021-1909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mn9686-14052021-1501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TYY5622-14052021-1609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TYY5630-14052021-1818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TYY9524-14052021-2029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mn9686-16052021-1443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TYY5630-16052021-1810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TYY5622-16052021-1621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sessionName\n",
       "0   mn9686-12052021-1702\n",
       "1  TYY5622-12052021-1805\n",
       "2  TYY5630-12052021-1909\n",
       "3   mn9686-14052021-1501\n",
       "4  TYY5622-14052021-1609\n",
       "5  TYY5630-14052021-1818\n",
       "6  TYY9524-14052021-2029\n",
       "7   mn9686-16052021-1443\n",
       "8  TYY5630-16052021-1810\n",
       "9  TYY5622-16052021-1621"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projectName=\"autopi_behavior_2021\"\n",
    "dataPath=\"/adata/projects/autopi_behavior_2021\"\n",
    "dlcModelPath=\"/adata/models\"\n",
    "bridgeModel1 =\"bridgeDetection_640_480-Allen-2021-02-10\"\n",
    "mouseLeverModel =\"arena_top-Allen-2019-10-30\"\n",
    "bridgeModel2 = \"bridgeDetection_480_480-Allen-2021-01-23\"\n",
    "arenaMinRadius= 190\n",
    "arenaMaxRadius= 230\n",
    "\n",
    "\n",
    "myProject = Project(name=projectName,dataPath=dataPath,dlcModelPath=dlcModelPath)\n",
    "\n",
    "# read a file with the session names\n",
    "fn=myProject.dataPath+\"/memory_sessions\"\n",
    "print(\"Reading \" + fn)\n",
    "sessionNamesTesting = pd.read_csv(fn) # this will be a pandas dataframe\n",
    "\n",
    "# create a list of session object in the project object\n",
    "myProject.createSessionList(sessionNameList=sessionNamesTesting.sessionName.to_list())\n",
    "print(\"We have {} recording sessions\".format(len(myProject.sessionList)))\n",
    "sessionNamesTesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function doing all the video processing and object tracking is in the file `video_utilities.py` of the `autopipy` package. \n",
    "The function is called `positionTrackingFromArenaTopVideo`.\n",
    "It relies on a 3 trained deeplabcut models to detect \n",
    "\n",
    "* 1) the bridge in 680x480 videos\n",
    "* 2) the mouse and lever in 480x480 videos\n",
    "* 3) the bridge in 480x480 videos\n",
    "\n",
    "You can set the path where these models are found and the name of the deeplabcut models via the function arguments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process a single session\n",
    "\n",
    "Let's start with a single session and make sure this works fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Startint at 20:39:56\n",
      "labelImage: /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-12052021-1909/arenaDetection.png\n",
      "/tmp/tmpVid.avi created for bridge detection\n",
      "Running dlc.analyze_video on /tmp/tmpVid.avi\n",
      "Using snapshot-460000 for model /adata/models/bridgeDetection_640_480-Allen-2021-02-10/dlc-models/iteration-0/bridgeDetection_640_480Feb10-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /tmp/tmpVid.avi\n",
      "/tmp  already exists!\n",
      "Loading  /tmp/tmpVid.avi\n",
      "Duration of video [s]:  16.67 , recorded with  30.0 fps!\n",
      "Overall # of frames:  500  found with (before cropping) frame dimensions:  640 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "510it [00:08, 61.68it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /tmp...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_640_480Feb10shuffle1_460000.h5\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_640_480Feb10shuffle1_460000.h5\n",
      "Saving position data to /tmp/tmpVidDLC_resnet_50_bridgeDetection_640_480Feb10shuffle1_460000.csv\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_640_480Feb10shuffle1_460000.h5\n",
      "Bridge coordinates: [[273   0]\n",
      " [273  15]\n",
      " [320  15]\n",
      " [320   0]]\n",
      "labelImage: /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-12052021-1909/bridgeDetection.png\n",
      "Time elapsed 0:00:20.604771\n",
      "Cropping and masking 109478 frames in /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-12052021-1909/TYY5630-12052021-1909.arena_top.avi\n",
      "Output file /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-12052021-1909/TYY5630-12052021-1909.arena_top.cropped.avi\n",
      "109470 of 109478 frames\n",
      "Exiting. Video saved as /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-12052021-1909/TYY5630-12052021-1909.arena_top.cropped.avi\n",
      "Time elapsed 0:08:02.701852\n",
      "Removing previous inference data: /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-12052021-1909/TYY5630-12052021-1909.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.h5\n",
      "Running dlc.analyze_video on /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-12052021-1909/TYY5630-12052021-1909.arena_top.cropped.avi\n",
      "Using snapshot-950000 for model /adata/models/arena_top-Allen-2019-10-30/dlc-models/iteration-0/arena_topOct30-trainset90shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/109478 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-12052021-1909/TYY5630-12052021-1909.arena_top.cropped.avi\n",
      "/adata/projects/autopi_behavior_2021/TYY5630/TYY5630-12052021-1909  already exists!\n",
      "Loading  /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-12052021-1909/TYY5630-12052021-1909.arena_top.cropped.avi\n",
      "Duration of video [s]:  3649.27 , recorded with  30.0 fps!\n",
      "Overall # of frames:  109478  found with (before cropping) frame dimensions:  480 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "110494it [17:55, 102.78it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-12052021-1909...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "dlc.loadPositionData() read data from /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-12052021-1909/TYY5630-12052021-1909.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.h5\n",
      "dlc.loadPositionData() read data from /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-12052021-1909/TYY5630-12052021-1909.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.h5\n",
      "Saving position data to /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-12052021-1909/TYY5630-12052021-1909.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.csv\n",
      "dlc.loadPositionData() read data from /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-12052021-1909/TYY5630-12052021-1909.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.h5\n",
      "Time elapsed 0:26:06.435350\n",
      "Time elapsed 0:26:06.435402\n",
      "labelImage: /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-12052021-1909/arenaDetectionCropped.png\n",
      "/tmp/tmpVid.avi created for bridge detection\n",
      "Running dlc.analyze_video on /tmp/tmpVid.avi\n",
      "Using snapshot-320000 for model /adata/models/bridgeDetection_480_480-Allen-2021-01-23/dlc-models/iteration-0/bridgeDetection_480_480Jan23-trainset90shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /tmp/tmpVid.avi\n",
      "/tmp  already exists!\n",
      "Loading  /tmp/tmpVid.avi\n",
      "Duration of video [s]:  16.67 , recorded with  30.0 fps!\n",
      "Overall # of frames:  500  found with (before cropping) frame dimensions:  480 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "510it [00:05, 85.12it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /tmp...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_320000.h5\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_320000.h5\n",
      "Saving position data to /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_320000.csv\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_320000.h5\n",
      "Bridge coordinates: [[204   0]\n",
      " [204  12]\n",
      " [255  12]\n",
      " [255   0]]\n",
      "labelImage: /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-12052021-1909/bridgeDetectionCropped.png\n",
      "labelImage: /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-12052021-1909/arenaBridgeDetectionCropped.png\n",
      "Ending at  21:06:18\n",
      "***Total duration: 0:26:21.929674 ***\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(autopipy.video_utilities)\n",
    "from autopipy.video_utilities import positionTrackingFromArenaTopVideo\n",
    "from autopipy.dlcObjectDetectors import MouseLeverDetector\n",
    "ses = myProject.sessionList[-1]\n",
    "positionTrackingFromArenaTopVideo(ses,modelDir=dlcModelPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Startint at 18:06:10\n",
      "labelImage: /adata/projects/autopi_behavior_2021/mn3246/mn3246-05032021-1534/arenaDetection.png\n",
      "/tmp/tmpVid.avi created for bridge detection\n",
      "Running dlc.analyze_video on /tmp/tmpVid.avi\n",
      "Using snapshot-460000 for model /adata/models/bridgeDetection_640_480-Allen-2021-02-10/dlc-models/iteration-0/bridgeDetection_640_480Feb10-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /tmp/tmpVid.avi\n",
      "/tmp  already exists!\n",
      "Loading  /tmp/tmpVid.avi\n",
      "Duration of video [s]:  16.67 , recorded with  30.0 fps!\n",
      "Overall # of frames:  500  found with (before cropping) frame dimensions:  640 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "510it [00:08, 59.19it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /tmp...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_640_480Feb10shuffle1_460000.h5\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_640_480Feb10shuffle1_460000.h5\n",
      "Saving position data to /tmp/tmpVidDLC_resnet_50_bridgeDetection_640_480Feb10shuffle1_460000.csv\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_640_480Feb10shuffle1_460000.h5\n",
      "Bridge coordinates: [[287   0]\n",
      " [287  29]\n",
      " [333  29]\n",
      " [333   0]]\n",
      "labelImage: /adata/projects/autopi_behavior_2021/mn3246/mn3246-05032021-1534/bridgeDetection.png\n",
      "Time elapsed 0:00:20.019249\n",
      "Cropping and masking 109687 frames in /adata/projects/autopi_behavior_2021/mn3246/mn3246-05032021-1534/mn3246-05032021-1534.arena_top.avi\n",
      "Output file /adata/projects/autopi_behavior_2021/mn3246/mn3246-05032021-1534/mn3246-05032021-1534.arena_top.cropped.avi\n",
      "109680 of 109687 frames\n",
      "Exiting. Video saved as /adata/projects/autopi_behavior_2021/mn3246/mn3246-05032021-1534/mn3246-05032021-1534.arena_top.cropped.avi\n",
      "Time elapsed 0:07:33.840477\n",
      "Removing previous inference data: /adata/projects/autopi_behavior_2021/mn3246/mn3246-05032021-1534/mn3246-05032021-1534.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.h5\n",
      "Running dlc.analyze_video on /adata/projects/autopi_behavior_2021/mn3246/mn3246-05032021-1534/mn3246-05032021-1534.arena_top.cropped.avi\n",
      "Using snapshot-950000 for model /adata/models/arena_top-Allen-2019-10-30/dlc-models/iteration-0/arena_topOct30-trainset90shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/109687 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /adata/projects/autopi_behavior_2021/mn3246/mn3246-05032021-1534/mn3246-05032021-1534.arena_top.cropped.avi\n",
      "/adata/projects/autopi_behavior_2021/mn3246/mn3246-05032021-1534  already exists!\n",
      "Loading  /adata/projects/autopi_behavior_2021/mn3246/mn3246-05032021-1534/mn3246-05032021-1534.arena_top.cropped.avi\n",
      "Duration of video [s]:  3656.23 , recorded with  30.0 fps!\n",
      "Overall # of frames:  109687  found with (before cropping) frame dimensions:  480 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "110696it [20:17, 90.90it/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /adata/projects/autopi_behavior_2021/mn3246/mn3246-05032021-1534...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "dlc.loadPositionData() read data from /adata/projects/autopi_behavior_2021/mn3246/mn3246-05032021-1534/mn3246-05032021-1534.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.h5\n",
      "dlc.loadPositionData() read data from /adata/projects/autopi_behavior_2021/mn3246/mn3246-05032021-1534/mn3246-05032021-1534.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.h5\n",
      "Saving position data to /adata/projects/autopi_behavior_2021/mn3246/mn3246-05032021-1534/mn3246-05032021-1534.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.csv\n",
      "dlc.loadPositionData() read data from /adata/projects/autopi_behavior_2021/mn3246/mn3246-05032021-1534/mn3246-05032021-1534.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.h5\n",
      "Time elapsed 0:28:00.191016\n",
      "Time elapsed 0:28:00.191079\n",
      "labelImage: /adata/projects/autopi_behavior_2021/mn3246/mn3246-05032021-1534/arenaDetectionCropped.png\n",
      "/tmp/tmpVid.avi created for bridge detection\n",
      "Running dlc.analyze_video on /tmp/tmpVid.avi\n",
      "Using snapshot-320000 for model /adata/models/bridgeDetection_480_480-Allen-2021-01-23/dlc-models/iteration-0/bridgeDetection_480_480Jan23-trainset90shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /tmp/tmpVid.avi\n",
      "/tmp  already exists!\n",
      "Loading  /tmp/tmpVid.avi\n",
      "Duration of video [s]:  16.67 , recorded with  30.0 fps!\n",
      "Overall # of frames:  500  found with (before cropping) frame dimensions:  480 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "510it [00:05, 86.99it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /tmp...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_320000.h5\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_320000.h5\n",
      "Saving position data to /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_320000.csv\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_320000.h5\n",
      "Bridge coordinates: [[206   0]\n",
      " [206  31]\n",
      " [256  31]\n",
      " [256   0]]\n",
      "labelImage: /adata/projects/autopi_behavior_2021/mn3246/mn3246-05032021-1534/bridgeDetectionCropped.png\n",
      "labelImage: /adata/projects/autopi_behavior_2021/mn3246/mn3246-05032021-1534/arenaBridgeDetectionCropped.png\n",
      "Ending at  18:34:25\n",
      "***Total duration: 0:28:14.943387 ***\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(autopipy.video_utilities)\n",
    "from autopipy.video_utilities import positionTrackingFromArenaTopVideo\n",
    "\n",
    "ses = myProject.sessionList[-1]\n",
    "positionTrackingFromArenaTopVideo(ses=ses,modelDir=myProject.dlcModelPath,\n",
    "                                  bridge640_480Model = bridgeModel1,\n",
    "                                  mouseLeverModel = mouseLeverModel,\n",
    "                                  bridge480_480Model = bridgeModel2,\n",
    "                                 arenaMinRadius=arenaMinRadius , arenaMaxRadius=arenaMaxRadius)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4416a1f0773b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmyProject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mn5183-13082020-1011\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/repo/autopipy/autopipy/project.py\u001b[0m in \u001b[0;36mgetSession\u001b[0;34m(self, sessionName)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mses\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mses\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msessionList\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0msessionName\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "myProject.getSession(\"mn5183-13082020-1011\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Startint at 10:15:52\n",
      "labelImage: /adata/projects/autopi_behavior_2021/mn7701/mn7701-19122019-1216/arenaDetection.png\n",
      "/tmp/tmpVid.avi created for bridge detection\n",
      "Running dlc.analyze_video on /tmp/tmpVid.avi\n",
      "Using snapshot-460000 for model /adata/models/bridgeDetection_640_480-Allen-2021-02-10/dlc-models/iteration-0/bridgeDetection_640_480Feb10-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /tmp/tmpVid.avi\n",
      "/tmp  already exists!\n",
      "Loading  /tmp/tmpVid.avi\n",
      "Duration of video [s]:  16.67 , recorded with  30.0 fps!\n",
      "Overall # of frames:  500  found with (before cropping) frame dimensions:  640 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "510it [00:08, 56.88it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /tmp...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_640_480Feb10shuffle1_460000.h5\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_640_480Feb10shuffle1_460000.h5\n",
      "Saving position data to /tmp/tmpVidDLC_resnet_50_bridgeDetection_640_480Feb10shuffle1_460000.csv\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_640_480Feb10shuffle1_460000.h5\n",
      "Bridge coordinates: [[293   0]\n",
      " [293  30]\n",
      " [335  30]\n",
      " [335   0]]\n",
      "labelImage: /adata/projects/autopi_behavior_2021/mn7701/mn7701-19122019-1216/bridgeDetection.png\n",
      "Time elapsed 0:00:21.893074\n",
      "Cropping and masking 106253 frames in /adata/projects/autopi_behavior_2021/mn7701/mn7701-19122019-1216/mn7701-19122019-1216.arena_top.avi\n",
      "Output file /adata/projects/autopi_behavior_2021/mn7701/mn7701-19122019-1216/mn7701-19122019-1216.arena_top.cropped.avi\n",
      "106250 of 106253 frames\n",
      "Exiting. Video saved as /adata/projects/autopi_behavior_2021/mn7701/mn7701-19122019-1216/mn7701-19122019-1216.arena_top.cropped.avi\n",
      "Time elapsed 0:08:42.511479\n",
      "Removing previous inference data: /adata/projects/autopi_behavior_2021/mn7701/mn7701-19122019-1216/mn7701-19122019-1216.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.h5\n",
      "Running dlc.analyze_video on /adata/projects/autopi_behavior_2021/mn7701/mn7701-19122019-1216/mn7701-19122019-1216.arena_top.cropped.avi\n",
      "Using snapshot-950000 for model /adata/models/arena_top-Allen-2019-10-30/dlc-models/iteration-0/arena_topOct30-trainset90shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/106253 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /adata/projects/autopi_behavior_2021/mn7701/mn7701-19122019-1216/mn7701-19122019-1216.arena_top.cropped.avi\n",
      "/adata/projects/autopi_behavior_2021/mn7701/mn7701-19122019-1216  already exists!\n",
      "Loading  /adata/projects/autopi_behavior_2021/mn7701/mn7701-19122019-1216/mn7701-19122019-1216.arena_top.cropped.avi\n",
      "Duration of video [s]:  3541.77 , recorded with  30.0 fps!\n",
      "Overall # of frames:  106253  found with (before cropping) frame dimensions:  480 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "107262it [19:31, 91.55it/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /adata/projects/autopi_behavior_2021/mn7701/mn7701-19122019-1216...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "dlc.loadPositionData() read data from /adata/projects/autopi_behavior_2021/mn7701/mn7701-19122019-1216/mn7701-19122019-1216.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.h5\n",
      "dlc.loadPositionData() read data from /adata/projects/autopi_behavior_2021/mn7701/mn7701-19122019-1216/mn7701-19122019-1216.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.h5\n",
      "Saving position data to /adata/projects/autopi_behavior_2021/mn7701/mn7701-19122019-1216/mn7701-19122019-1216.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.csv\n",
      "dlc.loadPositionData() read data from /adata/projects/autopi_behavior_2021/mn7701/mn7701-19122019-1216/mn7701-19122019-1216.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.h5\n",
      "Time elapsed 0:28:24.733522\n",
      "Time elapsed 0:28:24.733757\n",
      "labelImage: /adata/projects/autopi_behavior_2021/mn7701/mn7701-19122019-1216/arenaDetectionCropped.png\n",
      "/tmp/tmpVid.avi created for bridge detection\n",
      "Running dlc.analyze_video on /tmp/tmpVid.avi\n",
      "Using snapshot-320000 for model /adata/models/bridgeDetection_480_480-Allen-2021-01-23/dlc-models/iteration-0/bridgeDetection_480_480Jan23-trainset90shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /tmp/tmpVid.avi\n",
      "/tmp  already exists!\n",
      "Loading  /tmp/tmpVid.avi\n",
      "Duration of video [s]:  16.67 , recorded with  30.0 fps!\n",
      "Overall # of frames:  500  found with (before cropping) frame dimensions:  480 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "510it [00:05, 87.12it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /tmp...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_320000.h5\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_320000.h5\n",
      "Saving position data to /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_320000.csv\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_320000.h5\n",
      "Bridge coordinates: [[218   0]\n",
      " [218  30]\n",
      " [258  30]\n",
      " [258   0]]\n",
      "labelImage: /adata/projects/autopi_behavior_2021/mn7701/mn7701-19122019-1216/bridgeDetectionCropped.png\n",
      "labelImage: /adata/projects/autopi_behavior_2021/mn7701/mn7701-19122019-1216/arenaBridgeDetectionCropped.png\n",
      "Ending at  10:44:33\n",
      "***Total duration: 0:28:40.770847 ***\n",
      "Startint at 10:44:33\n",
      "labelImage: /adata/projects/autopi_behavior_2021/mn7711/mn7711-19122019-1429/arenaDetection.png\n",
      "/tmp/tmpVid.avi created for bridge detection\n",
      "Running dlc.analyze_video on /tmp/tmpVid.avi\n",
      "Using snapshot-460000 for model /adata/models/bridgeDetection_640_480-Allen-2021-02-10/dlc-models/iteration-0/bridgeDetection_640_480Feb10-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /tmp/tmpVid.avi\n",
      "/tmp  already exists!\n",
      "Loading  /tmp/tmpVid.avi\n",
      "Duration of video [s]:  16.67 , recorded with  30.0 fps!\n",
      "Overall # of frames:  500  found with (before cropping) frame dimensions:  640 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "510it [00:07, 67.45it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /tmp...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_640_480Feb10shuffle1_460000.h5\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_640_480Feb10shuffle1_460000.h5\n",
      "Saving position data to /tmp/tmpVidDLC_resnet_50_bridgeDetection_640_480Feb10shuffle1_460000.csv\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_640_480Feb10shuffle1_460000.h5\n",
      "Bridge coordinates: [[293   0]\n",
      " [293  29]\n",
      " [336  29]\n",
      " [336   0]]\n",
      "labelImage: /adata/projects/autopi_behavior_2021/mn7711/mn7711-19122019-1429/bridgeDetection.png\n",
      "Time elapsed 0:00:19.858398\n",
      "Cropping and masking 115401 frames in /adata/projects/autopi_behavior_2021/mn7711/mn7711-19122019-1429/mn7711-19122019-1429.arena_top.avi\n",
      "Output file /adata/projects/autopi_behavior_2021/mn7711/mn7711-19122019-1429/mn7711-19122019-1429.arena_top.cropped.avi\n",
      "115400 of 115401 frames\n",
      "Exiting. Video saved as /adata/projects/autopi_behavior_2021/mn7711/mn7711-19122019-1429/mn7711-19122019-1429.arena_top.cropped.avi\n",
      "Time elapsed 0:09:20.618546\n",
      "Removing previous inference data: /adata/projects/autopi_behavior_2021/mn7711/mn7711-19122019-1429/mn7711-19122019-1429.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.h5\n",
      "Running dlc.analyze_video on /adata/projects/autopi_behavior_2021/mn7711/mn7711-19122019-1429/mn7711-19122019-1429.arena_top.cropped.avi\n",
      "Using snapshot-950000 for model /adata/models/arena_top-Allen-2019-10-30/dlc-models/iteration-0/arena_topOct30-trainset90shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/115401 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /adata/projects/autopi_behavior_2021/mn7711/mn7711-19122019-1429/mn7711-19122019-1429.arena_top.cropped.avi\n",
      "/adata/projects/autopi_behavior_2021/mn7711/mn7711-19122019-1429  already exists!\n",
      "Loading  /adata/projects/autopi_behavior_2021/mn7711/mn7711-19122019-1429/mn7711-19122019-1429.arena_top.cropped.avi\n",
      "Duration of video [s]:  3846.7 , recorded with  30.0 fps!\n",
      "Overall # of frames:  115401  found with (before cropping) frame dimensions:  480 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "116554it [21:00, 92.47it/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /adata/projects/autopi_behavior_2021/mn7711/mn7711-19122019-1429...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "dlc.loadPositionData() read data from /adata/projects/autopi_behavior_2021/mn7711/mn7711-19122019-1429/mn7711-19122019-1429.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.h5\n",
      "dlc.loadPositionData() read data from /adata/projects/autopi_behavior_2021/mn7711/mn7711-19122019-1429/mn7711-19122019-1429.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.h5\n",
      "Saving position data to /adata/projects/autopi_behavior_2021/mn7711/mn7711-19122019-1429/mn7711-19122019-1429.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.csv\n",
      "dlc.loadPositionData() read data from /adata/projects/autopi_behavior_2021/mn7711/mn7711-19122019-1429/mn7711-19122019-1429.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.h5\n",
      "Time elapsed 0:30:32.158665\n",
      "Time elapsed 0:30:32.158718\n",
      "labelImage: /adata/projects/autopi_behavior_2021/mn7711/mn7711-19122019-1429/arenaDetectionCropped.png\n",
      "/tmp/tmpVid.avi created for bridge detection\n",
      "Running dlc.analyze_video on /tmp/tmpVid.avi\n",
      "Using snapshot-320000 for model /adata/models/bridgeDetection_480_480-Allen-2021-01-23/dlc-models/iteration-0/bridgeDetection_480_480Jan23-trainset90shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /tmp/tmpVid.avi\n",
      "/tmp  already exists!\n",
      "Loading  /tmp/tmpVid.avi\n",
      "Duration of video [s]:  16.67 , recorded with  30.0 fps!\n",
      "Overall # of frames:  500  found with (before cropping) frame dimensions:  480 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "510it [00:05, 85.07it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /tmp...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_320000.h5\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_320000.h5\n",
      "Saving position data to /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_320000.csv\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_320000.h5\n",
      "Bridge coordinates: [[218   0]\n",
      " [218  29]\n",
      " [260  29]\n",
      " [260   0]]\n",
      "labelImage: /adata/projects/autopi_behavior_2021/mn7711/mn7711-19122019-1429/bridgeDetectionCropped.png\n",
      "labelImage: /adata/projects/autopi_behavior_2021/mn7711/mn7711-19122019-1429/arenaBridgeDetectionCropped.png\n",
      "Ending at  11:15:20\n",
      "***Total duration: 0:30:47.170353 ***\n"
     ]
    }
   ],
   "source": [
    "## Sessions to re-run with new network\n",
    "sesNameList = [\"mn7701-19122019-1216\",\"mn7711-19122019-1429\"]\n",
    "for sesName in sesNameList:\n",
    "    ses=myProject.getSession(sesName)\n",
    "    positionTrackingFromArenaTopVideo(ses=ses,modelDir=myProject.dlcModelPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group of sessions\n",
    "And to run a group of sessions, simply run this in a for loop. I will save the session name in a file to keep track of what is done.\n",
    "\n",
    "pc73 from home.\n",
    "Friday: I did 0:10 as a first try and worked great. 5%\n",
    "Friday: I tried 10:40 overnight to test overnight vpn connection, manage to do 32 sessions. \n",
    "\n",
    "It is too slow if run only on one computer.\n",
    "pc59 and pc 73\n",
    "\n",
    "* pc73: [32:100]\n",
    "* pc59: [100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Startint at 21:17:46\n",
      "labelImage: /adata/projects/autopi_behavior_2021/mn9686/mn9686-16052021-1443/arenaDetection.png\n",
      "/tmp/tmpVid.avi created for bridge detection\n",
      "Running dlc.analyze_video on /tmp/tmpVid.avi\n",
      "Using snapshot-460000 for model /adata/models/bridgeDetection_640_480-Allen-2021-02-10/dlc-models/iteration-0/bridgeDetection_640_480Feb10-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /tmp/tmpVid.avi\n",
      "/tmp  already exists!\n",
      "Loading  /tmp/tmpVid.avi\n",
      "Duration of video [s]:  16.67 , recorded with  30.0 fps!\n",
      "Overall # of frames:  500  found with (before cropping) frame dimensions:  640 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "510it [00:08, 59.24it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /tmp...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_640_480Feb10shuffle1_460000.h5\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_640_480Feb10shuffle1_460000.h5\n",
      "Saving position data to /tmp/tmpVidDLC_resnet_50_bridgeDetection_640_480Feb10shuffle1_460000.csv\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_640_480Feb10shuffle1_460000.h5\n",
      "Bridge coordinates: [[270   0]\n",
      " [270  22]\n",
      " [323  22]\n",
      " [323   0]]\n",
      "labelImage: /adata/projects/autopi_behavior_2021/mn9686/mn9686-16052021-1443/bridgeDetection.png\n",
      "Time elapsed 0:00:20.049256\n",
      "Cropping and masking 157232 frames in /adata/projects/autopi_behavior_2021/mn9686/mn9686-16052021-1443/mn9686-16052021-1443.arena_top.avi\n",
      "Output file /adata/projects/autopi_behavior_2021/mn9686/mn9686-16052021-1443/mn9686-16052021-1443.arena_top.cropped.avi\n",
      "157230 of 157232 frames\n",
      "Exiting. Video saved as /adata/projects/autopi_behavior_2021/mn9686/mn9686-16052021-1443/mn9686-16052021-1443.arena_top.cropped.avi\n",
      "Time elapsed 0:09:49.695165\n",
      "Removing previous inference data: /adata/projects/autopi_behavior_2021/mn9686/mn9686-16052021-1443/mn9686-16052021-1443.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.h5\n",
      "Running dlc.analyze_video on /adata/projects/autopi_behavior_2021/mn9686/mn9686-16052021-1443/mn9686-16052021-1443.arena_top.cropped.avi\n",
      "Using snapshot-950000 for model /adata/models/arena_top-Allen-2019-10-30/dlc-models/iteration-0/arena_topOct30-trainset90shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/157232 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /adata/projects/autopi_behavior_2021/mn9686/mn9686-16052021-1443/mn9686-16052021-1443.arena_top.cropped.avi\n",
      "/adata/projects/autopi_behavior_2021/mn9686/mn9686-16052021-1443  already exists!\n",
      "Loading  /adata/projects/autopi_behavior_2021/mn9686/mn9686-16052021-1443/mn9686-16052021-1443.arena_top.cropped.avi\n",
      "Duration of video [s]:  5241.07 , recorded with  30.0 fps!\n",
      "Overall # of frames:  157232  found with (before cropping) frame dimensions:  480 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "158772it [29:31, 89.62it/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /adata/projects/autopi_behavior_2021/mn9686/mn9686-16052021-1443...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "dlc.loadPositionData() read data from /adata/projects/autopi_behavior_2021/mn9686/mn9686-16052021-1443/mn9686-16052021-1443.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.h5\n",
      "dlc.loadPositionData() read data from /adata/projects/autopi_behavior_2021/mn9686/mn9686-16052021-1443/mn9686-16052021-1443.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.h5\n",
      "Saving position data to /adata/projects/autopi_behavior_2021/mn9686/mn9686-16052021-1443/mn9686-16052021-1443.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.csv\n",
      "dlc.loadPositionData() read data from /adata/projects/autopi_behavior_2021/mn9686/mn9686-16052021-1443/mn9686-16052021-1443.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.h5\n",
      "Time elapsed 0:39:31.634835\n",
      "Time elapsed 0:39:31.634885\n",
      "labelImage: /adata/projects/autopi_behavior_2021/mn9686/mn9686-16052021-1443/arenaDetectionCropped.png\n",
      "/tmp/tmpVid.avi created for bridge detection\n",
      "Running dlc.analyze_video on /tmp/tmpVid.avi\n",
      "Using snapshot-320000 for model /adata/models/bridgeDetection_480_480-Allen-2021-01-23/dlc-models/iteration-0/bridgeDetection_480_480Jan23-trainset90shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /tmp/tmpVid.avi\n",
      "/tmp  already exists!\n",
      "Loading  /tmp/tmpVid.avi\n",
      "Duration of video [s]:  16.67 , recorded with  30.0 fps!\n",
      "Overall # of frames:  500  found with (before cropping) frame dimensions:  480 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "510it [00:06, 84.04it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /tmp...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_320000.h5\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_320000.h5\n",
      "Saving position data to /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_320000.csv\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_320000.h5\n",
      "Bridge coordinates: [[209   0]\n",
      " [209  24]\n",
      " [262  24]\n",
      " [262   0]]\n",
      "labelImage: /adata/projects/autopi_behavior_2021/mn9686/mn9686-16052021-1443/bridgeDetectionCropped.png\n",
      "labelImage: /adata/projects/autopi_behavior_2021/mn9686/mn9686-16052021-1443/arenaBridgeDetectionCropped.png\n",
      "Ending at  21:57:33\n",
      "***Total duration: 0:39:47.000878 ***\n",
      "Startint at 21:57:33\n",
      "labelImage: /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-16052021-1810/arenaDetection.png\n",
      "/tmp/tmpVid.avi created for bridge detection\n",
      "Running dlc.analyze_video on /tmp/tmpVid.avi\n",
      "Using snapshot-460000 for model /adata/models/bridgeDetection_640_480-Allen-2021-02-10/dlc-models/iteration-0/bridgeDetection_640_480Feb10-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /tmp/tmpVid.avi\n",
      "/tmp  already exists!\n",
      "Loading  /tmp/tmpVid.avi\n",
      "Duration of video [s]:  16.67 , recorded with  30.0 fps!\n",
      "Overall # of frames:  500  found with (before cropping) frame dimensions:  640 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "510it [00:07, 67.90it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /tmp...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_640_480Feb10shuffle1_460000.h5\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_640_480Feb10shuffle1_460000.h5\n",
      "Saving position data to /tmp/tmpVidDLC_resnet_50_bridgeDetection_640_480Feb10shuffle1_460000.csv\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_640_480Feb10shuffle1_460000.h5\n",
      "Bridge coordinates: [[270   0]\n",
      " [270  24]\n",
      " [323  24]\n",
      " [323   0]]\n",
      "labelImage: /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-16052021-1810/bridgeDetection.png\n",
      "Time elapsed 0:00:18.316951\n",
      "Cropping and masking -276701161105643264 frames in /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-16052021-1810/TYY5630-16052021-1810.arena_top.avi\n",
      "Output file /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-16052021-1810/TYY5630-16052021-1810.arena_top.cropped.avi\n",
      "112610 of -276701161105643264 frames\n",
      "Exiting. Video saved as /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-16052021-1810/TYY5630-16052021-1810.arena_top.cropped.avi\n",
      "Time elapsed 0:07:04.245406\n",
      "Removing previous inference data: /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-16052021-1810/TYY5630-16052021-1810.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.h5\n",
      "Running dlc.analyze_video on /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-16052021-1810/TYY5630-16052021-1810.arena_top.cropped.avi\n",
      "Using snapshot-950000 for model /adata/models/arena_top-Allen-2019-10-30/dlc-models/iteration-0/arena_topOct30-trainset90shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/112620 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-16052021-1810/TYY5630-16052021-1810.arena_top.cropped.avi\n",
      "/adata/projects/autopi_behavior_2021/TYY5630/TYY5630-16052021-1810  already exists!\n",
      "Loading  /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-16052021-1810/TYY5630-16052021-1810.arena_top.cropped.avi\n",
      "Duration of video [s]:  3754.0 , recorded with  30.0 fps!\n",
      "Overall # of frames:  112620  found with (before cropping) frame dimensions:  480 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113726it [20:06, 94.24it/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-16052021-1810...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "dlc.loadPositionData() read data from /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-16052021-1810/TYY5630-16052021-1810.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.h5\n",
      "dlc.loadPositionData() read data from /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-16052021-1810/TYY5630-16052021-1810.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.h5\n",
      "Saving position data to /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-16052021-1810/TYY5630-16052021-1810.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.csv\n",
      "dlc.loadPositionData() read data from /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-16052021-1810/TYY5630-16052021-1810.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.h5\n",
      "Time elapsed 0:27:20.011396\n",
      "Time elapsed 0:27:20.011445\n",
      "labelImage: /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-16052021-1810/arenaDetectionCropped.png\n",
      "/tmp/tmpVid.avi created for bridge detection\n",
      "Running dlc.analyze_video on /tmp/tmpVid.avi\n",
      "Using snapshot-320000 for model /adata/models/bridgeDetection_480_480-Allen-2021-01-23/dlc-models/iteration-0/bridgeDetection_480_480Jan23-trainset90shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /tmp/tmpVid.avi\n",
      "/tmp  already exists!\n",
      "Loading  /tmp/tmpVid.avi\n",
      "Duration of video [s]:  16.67 , recorded with  30.0 fps!\n",
      "Overall # of frames:  500  found with (before cropping) frame dimensions:  480 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "510it [00:05, 86.61it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /tmp...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_320000.h5\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_320000.h5\n",
      "Saving position data to /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_320000.csv\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_320000.h5\n",
      "Bridge coordinates: [[205   0]\n",
      " [205  23]\n",
      " [256  23]\n",
      " [256   0]]\n",
      "labelImage: /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-16052021-1810/bridgeDetectionCropped.png\n",
      "labelImage: /adata/projects/autopi_behavior_2021/TYY5630/TYY5630-16052021-1810/arenaBridgeDetectionCropped.png\n",
      "Ending at  22:25:08\n",
      "***Total duration: 0:27:35.103726 ***\n",
      "Startint at 22:25:08\n",
      "labelImage: /adata/projects/autopi_behavior_2021/TYY5622/TYY5622-16052021-1621/arenaDetection.png\n",
      "/tmp/tmpVid.avi created for bridge detection\n",
      "Running dlc.analyze_video on /tmp/tmpVid.avi\n",
      "Using snapshot-460000 for model /adata/models/bridgeDetection_640_480-Allen-2021-02-10/dlc-models/iteration-0/bridgeDetection_640_480Feb10-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /tmp/tmpVid.avi\n",
      "/tmp  already exists!\n",
      "Loading  /tmp/tmpVid.avi\n",
      "Duration of video [s]:  16.67 , recorded with  30.0 fps!\n",
      "Overall # of frames:  500  found with (before cropping) frame dimensions:  640 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "510it [00:07, 68.62it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /tmp...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_640_480Feb10shuffle1_460000.h5\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_640_480Feb10shuffle1_460000.h5\n",
      "Saving position data to /tmp/tmpVidDLC_resnet_50_bridgeDetection_640_480Feb10shuffle1_460000.csv\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_640_480Feb10shuffle1_460000.h5\n",
      "Bridge coordinates: [[270   0]\n",
      " [270  23]\n",
      " [322  23]\n",
      " [322   0]]\n",
      "labelImage: /adata/projects/autopi_behavior_2021/TYY5622/TYY5622-16052021-1621/bridgeDetection.png\n",
      "Time elapsed 0:00:18.260521\n",
      "Cropping and masking 102025 frames in /adata/projects/autopi_behavior_2021/TYY5622/TYY5622-16052021-1621/TYY5622-16052021-1621.arena_top.avi\n",
      "Output file /adata/projects/autopi_behavior_2021/TYY5622/TYY5622-16052021-1621/TYY5622-16052021-1621.arena_top.cropped.avi\n",
      "102020 of 102025 frames\n",
      "Exiting. Video saved as /adata/projects/autopi_behavior_2021/TYY5622/TYY5622-16052021-1621/TYY5622-16052021-1621.arena_top.cropped.avi\n",
      "Time elapsed 0:06:26.847890\n",
      "Removing previous inference data: /adata/projects/autopi_behavior_2021/TYY5622/TYY5622-16052021-1621/TYY5622-16052021-1621.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.h5\n",
      "Running dlc.analyze_video on /adata/projects/autopi_behavior_2021/TYY5622/TYY5622-16052021-1621/TYY5622-16052021-1621.arena_top.cropped.avi\n",
      "Using snapshot-950000 for model /adata/models/arena_top-Allen-2019-10-30/dlc-models/iteration-0/arena_topOct30-trainset90shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/102025 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /adata/projects/autopi_behavior_2021/TYY5622/TYY5622-16052021-1621/TYY5622-16052021-1621.arena_top.cropped.avi\n",
      "/adata/projects/autopi_behavior_2021/TYY5622/TYY5622-16052021-1621  already exists!\n",
      "Loading  /adata/projects/autopi_behavior_2021/TYY5622/TYY5622-16052021-1621/TYY5622-16052021-1621.arena_top.cropped.avi\n",
      "Duration of video [s]:  3400.83 , recorded with  30.0 fps!\n",
      "Overall # of frames:  102025  found with (before cropping) frame dimensions:  480 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103020it [18:14, 94.13it/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /adata/projects/autopi_behavior_2021/TYY5622/TYY5622-16052021-1621...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "dlc.loadPositionData() read data from /adata/projects/autopi_behavior_2021/TYY5622/TYY5622-16052021-1621/TYY5622-16052021-1621.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.h5\n",
      "dlc.loadPositionData() read data from /adata/projects/autopi_behavior_2021/TYY5622/TYY5622-16052021-1621/TYY5622-16052021-1621.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.h5\n",
      "Saving position data to /adata/projects/autopi_behavior_2021/TYY5622/TYY5622-16052021-1621/TYY5622-16052021-1621.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.csv\n",
      "dlc.loadPositionData() read data from /adata/projects/autopi_behavior_2021/TYY5622/TYY5622-16052021-1621/TYY5622-16052021-1621.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_950000.h5\n",
      "Time elapsed 0:24:49.503714\n",
      "Time elapsed 0:24:49.503764\n",
      "labelImage: /adata/projects/autopi_behavior_2021/TYY5622/TYY5622-16052021-1621/arenaDetectionCropped.png\n",
      "/tmp/tmpVid.avi created for bridge detection\n",
      "Running dlc.analyze_video on /tmp/tmpVid.avi\n",
      "Using snapshot-320000 for model /adata/models/bridgeDetection_480_480-Allen-2021-01-23/dlc-models/iteration-0/bridgeDetection_480_480Jan23-trainset90shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /tmp/tmpVid.avi\n",
      "/tmp  already exists!\n",
      "Loading  /tmp/tmpVid.avi\n",
      "Duration of video [s]:  16.67 , recorded with  30.0 fps!\n",
      "Overall # of frames:  500  found with (before cropping) frame dimensions:  480 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "510it [00:05, 90.44it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /tmp...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_320000.h5\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_320000.h5\n",
      "Saving position data to /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_320000.csv\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_320000.h5\n",
      "Bridge coordinates: [[213   0]\n",
      " [213  23]\n",
      " [264  23]\n",
      " [264   0]]\n",
      "labelImage: /adata/projects/autopi_behavior_2021/TYY5622/TYY5622-16052021-1621/bridgeDetectionCropped.png\n",
      "labelImage: /adata/projects/autopi_behavior_2021/TYY5622/TYY5622-16052021-1621/arenaBridgeDetectionCropped.png\n",
      "Ending at  22:50:13\n",
      "***Total duration: 0:25:04.451437 ***\n"
     ]
    }
   ],
   "source": [
    "for ses in myProject.sessionList[7:] :\n",
    "    positionTrackingFromArenaTopVideo(ses=ses,modelDir=myProject.dlcModelPath)\n",
    "   # text_file = open(myProject.dataPath+\"/results/dlcDone\", \"a\")\n",
    "   # text_file.write(\"{}\\n\".format(ses.name))\n",
    "   # text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ses in myProject.sessionList[100:] :\n",
    "    positionTrackingFromArenaTopVideo(ses=ses,modelDir=myProject.dlcModelPath)\n",
    "    text_file = open(myProject.dataPath+\"/results/dlcDone\", \"a\")\n",
    "    text_file.write(\"{}\\n\".format(ses.name))\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that all went fine\n",
    "\n",
    "First we will make sure that we have all session names in the `dlcDone` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sessions: 187, processed sessions: 188\n",
      "All sessions processed\n"
     ]
    }
   ],
   "source": [
    "done = pd.read_csv(myProject.dataPath+\"/results/dlcDone\",header=None)\n",
    "sessionNamesTesting\n",
    "print(\"Number of sessions: {}, processed sessions: {}\".format(len(sessionNamesTesting),len(done)))\n",
    "if len(sessionNamesTesting) > len(done) :\n",
    "    print(\"Missing sessions are:\")\n",
    "    print(sessionNamesTesting.sessionName[~sessionNamesTesting.sessionName.isin(done[0])])\n",
    "\n",
    "if np.all(sessionNamesTesting.sessionName.isin(done[0])) :\n",
    "    print(\"All sessions processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check bridge and arena detection\n",
    "\n",
    "The bridge and arena coordinates are critical for the subsequent analysis. We will make a folder containing an image of the detection for each session. One can then quickly scroll through the images to identify any problematic case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a directory for the images\n",
    "directory = myProject.dataPath + \"/results/arenaBridgeDetectionImages\"\n",
    "try:\n",
    "    os.stat(directory)\n",
    "except:\n",
    "    os.mkdir(directory)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "\n",
    "for ses in myProject.sessionList:\n",
    "    src = ses.path + \"/arenaBridgeDetectionCropped.png\"\n",
    "    dst = directory + \"/\" + ses.name + \".png\"\n",
    "    if not os.path.isfile(src):\n",
    "        print (src + \" does not exist\")\n",
    "        break\n",
    "    try:\n",
    "        copyfile(src, dst)\n",
    "    except:\n",
    "        print(\"error copying the file for \" + ses.name )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rerun problematic sessions\n",
    "\n",
    "I put the sessions with problems in a file in the `results/redo`\n",
    "\n",
    "The main problem was the arena detection that was not perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project name: autopi_behavior_2021\n",
      "dataPath: /adata/projects/autopi_behavior_2021\n",
      "dlcModelPath: /adata/models\n",
      "Reading /adata/projects/autopi_behavior_2021/redo\n",
      "We have 4 recording sessions\n"
     ]
    }
   ],
   "source": [
    "projectName=\"autopi_behavior_2021\"\n",
    "dataPath=\"/adata/projects/autopi_behavior_2021\"\n",
    "dlcModelPath=\"/adata/models\"\n",
    "bridgeModel1 =\"bridgeDetection_640_480-Allen-2021-02-10\"\n",
    "mouseLeverModel =\"arena_top-Allen-2019-10-30\"\n",
    "bridgeModel2 = \"bridgeDetection_480_480-Allen-2021-01-23\"\n",
    "arenaMinRadius= 190\n",
    "arenaMaxRadius= 230\n",
    "\n",
    "myProject = Project(name=projectName,dataPath=dataPath,dlcModelPath=dlcModelPath)\n",
    "\n",
    "# read a file with the session names\n",
    "fn=myProject.dataPath+\"/redo\"\n",
    "print(\"Reading \" + fn)\n",
    "sessionNamesTesting = pd.read_csv(fn) # this will be a pandas dataframe\n",
    "\n",
    "# create a list of session object in the project object\n",
    "myProject.createSessionList(sessionNameList=sessionNamesTesting.sessionName.to_list())\n",
    "print(\"We have {} recording sessions\".format(len(myProject.sessionList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = myProject.dataPath + \"/results/arenaDetectionImages\"\n",
    "try:\n",
    "    os.stat(directory)\n",
    "except:\n",
    "    os.mkdir(directory)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "positionTrackingFromArenaTopVideo() got an unexpected keyword argument 'arenaCircleMethod'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-bd5eec4bfc43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                       \u001b[0mbridge480_480Model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbridgeModel2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                       \u001b[0marenaMinRadius\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marenaMinRadius\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0marenaMaxRadius\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marenaMaxRadius\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                                       arenaCircleMethod=\"median\")\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: positionTrackingFromArenaTopVideo() got an unexpected keyword argument 'arenaCircleMethod'"
     ]
    }
   ],
   "source": [
    "from autopipy.cvObjectDetectors import ArenaDetector\n",
    "from datetime import datetime\n",
    "\n",
    "for ses in myProject.sessionList :\n",
    "    positionTrackingFromArenaTopVideo(ses=ses,modelDir=myProject.dlcModelPath,\n",
    "                                      bridge640_480Model = bridgeModel1,\n",
    "                                      mouseLeverModel = mouseLeverModel,\n",
    "                                      bridge480_480Model = bridgeModel2,\n",
    "                                      arenaMinRadius=arenaMinRadius , arenaMaxRadius=arenaMaxRadius,\n",
    "                                      arenaCircleMethod=\"median\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/adata/models\n",
      "arena_top-Allen-2019-10-30\n",
      "labelImage: /adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/arenaDetectionCropped.png\n",
      "dlc.loadPositionData() read data from /adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/mn4656-30092019-2001.arena_top.croppedDLC_resnet_50_arena_topOct30shuffle1_1030000.h5\n",
      "/tmp/tmpVid.avi created for bridge detection\n",
      "Running dlc.analyze_video on /tmp/tmpVid.avi\n",
      "Using snapshot-420000 for model /adata/models/bridgeDetection_480_480-Allen-2021-01-23/dlc-models/iteration-0/bridgeDetection_480_480Jan23-trainset90shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /tmp/tmpVid.avi\n",
      "/tmp  already exists!\n",
      "Loading  /tmp/tmpVid.avi\n",
      "Duration of video [s]:  3.33 , recorded with  30.0 fps!\n",
      "Overall # of frames:  100  found with (before cropping) frame dimensions:  480 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "110it [00:01, 59.72it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  100\n",
      "Saving results in /tmp...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_420000.h5\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_420000.h5\n",
      "Saving position data to /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_420000.csv\n",
      "dlc.loadPositionData() read data from /tmp/tmpVidDLC_resnet_50_bridgeDetection_480_480Jan23shuffle1_420000.h5\n",
      "Bridge coordinates: [[220   0]\n",
      " [220  24]\n",
      " [259  24]\n",
      " [259   0]]\n",
      "labelImage: /adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/bridgeDetectionCropped.png\n",
      "labelImage: /adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/arenaBridgeDetectionCropped.png\n"
     ]
    }
   ],
   "source": [
    "from autopipy.cvObjectDetectors import ArenaDetector\n",
    "from autopipy.dlcObjectDetectors import BridgeDetector\n",
    "from autopipy.dlcObjectDetectors import MouseLeverDetector\n",
    "from autopipy.video_utilities import arenaBridgeDetectionImage\n",
    "from datetime import datetime\n",
    "\n",
    "modelDir=\"/adata/models\"\n",
    "bridge640_480Model = \"bridgeDetection_640_480-Allen-2021-02-10\"\n",
    "mouseLeverModel = \"arena_top-Allen-2019-10-30\"\n",
    "bridge480_480Model = \"bridgeDetection_480_480-Allen-2021-01-23\"\n",
    "arenaMinRadius= 180\n",
    "arenaMaxRadius= 230\n",
    "arenaCircleMethod = \"min\"\n",
    "numFramesArenaDetection=500\n",
    "numFramesBridgeDetection=500\n",
    "\n",
    "print(modelDir)\n",
    "print(mouseLeverModel)\n",
    "configFile=modelDir+\"/\"+ mouseLeverModel + \"/config.yaml\"\n",
    "\n",
    "\n",
    "for ses in [myProject.sessionList[0]] :\n",
    "    \n",
    "    videoFile=ses.fileNames[\"arena_top.avi\"]\n",
    "    croppedVideoFile = os.path.splitext(videoFile)[0]+\".cropped.avi\"\n",
    "    arenaImageFile=ses.path+\"/arenaDetectionCropped.png\"\n",
    "    bridge480_480Model=bridgeModel2\n",
    "    modelDir = dlcModelPath\n",
    "    \n",
    "    \n",
    "    arenaD = ArenaDetector()\n",
    "    aCoord = arenaD.detectArenaCoordinates(pathVideoFile=croppedVideoFile, minRadius=arenaMinRadius, \n",
    "                                  maxRadius=arenaMaxRadius, numFrames=100, blur=11, circleMethod='median')\n",
    "    arenaD.labelImage(pathVideoFile=croppedVideoFile,outputImageFile=arenaImageFile)\n",
    "    np.savetxt(ses.fileNames[\"arenaCoordinates\"],aCoord,delimiter=\",\") \n",
    "\n",
    "\n",
    "    configFile=modelDir+\"/\"+ mouseLeverModel + \"/config.yaml\"\n",
    "    if not os.path.isfile(configFile):\n",
    "        print(configFile+ \" is missing\")\n",
    "    mouseLeverD = MouseLeverDetector(pathConfigFile=configFile)\n",
    "    # save position data to file\n",
    "    mouseLeverD.savePositionOrientationToFile(pathVideoFile=croppedVideoFile, \n",
    "                                              fileName = ses.fileNames[\"mouseLeverPosition.csv\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "    configFile = modelDir + \"/\" + bridge480_480Model + \"/config.yaml\"\n",
    "    if not os.path.isfile(configFile):\n",
    "        print(configFile+ \" is missing\")\n",
    "    bridgeImageFile = ses.path+\"/bridgeDetectionCropped.png\"\n",
    "    bridgeD = BridgeDetector(pathConfigFile=configFile)\n",
    "    bCoord = bridgeD.detectBridgeCoordinates(pathVideoFile=croppedVideoFile,numFrames=100, skip=30)\n",
    "    bridgeD.labelImage(pathVideoFile=videoFile,outputImageFile=bridgeImageFile)\n",
    "    np.savetxt(ses.fileNames[\"bridgeCoordinates\"],bCoord,delimiter=\",\")\n",
    "    \n",
    "    outputImageFile=ses.path+\"/arenaBridgeDetectionCropped.png\"\n",
    "    arenaBridgeDetectionImage(pathVideoFile=croppedVideoFile,\n",
    "                              outputImageFile=outputImageFile,\n",
    "                              arenaCoordinates = aCoord,\n",
    "                              bridgeCoordinates = bCoord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
