{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "interstate-pearl",
   "metadata": {},
   "source": [
    "# Example of trial videos\n",
    "\n",
    "This will be included in presentations and manuscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "universal-prison",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "import shutil\n",
    "from autopipy.project import Project\n",
    "\n",
    "import importlib\n",
    "import autopipy\n",
    "importlib.reload(autopipy.project)\n",
    "importlib.reload(autopipy.session)\n",
    "importlib.reload(autopipy.navPath)\n",
    "importlib.reload(autopipy.trial)\n",
    "importlib.reload(autopipy.lever)\n",
    "\n",
    "from autopipy.session import Session\n",
    "from autopipy.project import Project\n",
    "from autopipy.trial import Trial\n",
    "from autopipy.navPath import NavPath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-copper",
   "metadata": {},
   "source": [
    "We first start by loading our project so that we can get a session from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "through-display",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project name: autopi_behavior_2021\n",
      "dataPath: /adata/projects/autopi_behavior_2021\n",
      "dlcModelPath: /adata/models\n"
     ]
    }
   ],
   "source": [
    "projectName=\"autopi_behavior_2021\"\n",
    "dataPath=\"/adata/projects/autopi_behavior_2021\"\n",
    "dlcModelPath=\"/adata/models\"\n",
    "myProject = Project(name=projectName,dataPath=dataPath,dlcModelPath=dlcModelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "located-measure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /adata/projects/autopi_behavior_2021/testing_sessions\n",
      "We have 67 recording sessions\n"
     ]
    }
   ],
   "source": [
    "fn=myProject.dataPath+\"/testing_sessions\"\n",
    "print(\"Reading \" + fn)\n",
    "sessionNamesTesting = pd.read_csv(fn) # this will be a pandas dataframe\n",
    "myProject.createSessionList(sessionNameList=sessionNamesTesting.sessionName.to_list())\n",
    "print(\"We have {} recording sessions\".format(len(myProject.sessionList)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-russian",
   "metadata": {},
   "source": [
    "We will select a session for which we will make the video for all trials, giving us a good range for selection.\n",
    "\n",
    "We can quickly scroll through the trial plot to make a first selection, then have a look at the possible videos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "hearing-entrepreneur",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mn4656-30092019-2001 trial segmentation\n",
      "Remove door closing event at the beginning of the session, index 55\n",
      "problem with the door alternation\n",
      "Problem with index 1413\n",
      "Removing the second of two door closings (index :1413)\n",
      "Problem with index 1557\n",
      "Removing the second of two door closings (index :1557)\n",
      "Number of trials : 79\n",
      "mn4656-30092019-2001, video len: 108125, video-log:0, first frame: 0, max log gap: nan, mean time diff: 0.0337, max time diff: 0.103, num problem diff: 0, frame rate: 29.7\n",
      "Lenght of mouseLeverPosi: 108125\n",
      "Lenght of videoLog: 108125\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "mn4656-30092019-2001_18, self.startTime was adjusted by -0.2 s\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "mn4656-30092019-2001_26, self.startTime was adjusted by -0.2 s\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "mn4656-30092019-2001_32, self.startTime was adjusted by -0.2 s\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "mn4656-30092019-2001_34, self.startTime was adjusted by -0.2 s\n",
      "trial feature extraction\n",
      "mn4656-30092019-2001_35-5, homingPeriNoLeverPose path has a length < 2\n",
      "trial feature extraction\n",
      "mn4656-30092019-2001_36, self.startTime was adjusted by -0.2 s\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "mn4656-30092019-2001_38, self.startTime was adjusted by -0.1 s\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "mn4656-30092019-2001_40, self.startTime was adjusted by -0.2 s\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "mn4656-30092019-2001_42, self.startTime was adjusted by -0.2 s\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "mn4656-30092019-2001_44, self.startTime was adjusted by -0.2 s\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "mn4656-30092019-2001_46, self.startTime was adjusted by -0.2 s\n",
      "trial feature extraction\n",
      "mn4656-30092019-2001_47, self.startTime was adjusted by -0.1 s\n",
      "trial feature extraction\n",
      "mn4656-30092019-2001_48, self.startTime was adjusted by -0.2 s\n",
      "trial feature extraction\n",
      "mn4656-30092019-2001_49, self.startTime was adjusted by -0.1 s\n",
      "trial feature extraction\n",
      "mn4656-30092019-2001_50, self.startTime was adjusted by -0.2 s\n",
      "trial feature extraction\n",
      "mn4656-30092019-2001_51, self.startTime was adjusted by -0.2 s\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "mn4656-30092019-2001_53, self.startTime was adjusted by -0.2 s\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "mn4656-30092019-2001_55, self.startTime was adjusted by -0.2 s\n",
      "trial feature extraction\n",
      "mn4656-30092019-2001_56, self.startTime was adjusted by -0.3 s\n",
      "trial feature extraction\n",
      "mn4656-30092019-2001_57, self.startTime was adjusted by -0.2 s\n",
      "trial feature extraction\n",
      "mn4656-30092019-2001_58, self.startTime was adjusted by -0.2 s\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "mn4656-30092019-2001_60, self.startTime was adjusted by -0.2 s\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "mn4656-30092019-2001_62, self.startTime was adjusted by -0.2 s\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "mn4656-30092019-2001_68, self.startTime was adjusted by -0.2 s\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "mn4656-30092019-2001_70, self.startTime was adjusted by -0.2 s\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "mn4656-30092019-2001_72, self.startTime was adjusted by -0.2 s\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "trial feature extraction\n",
      "mn4656-30092019-2001_78, self.startTime was adjusted by -0.3 s\n",
      "trial feature extraction\n",
      "mn4656-30092019-2001_79, self.startTime was adjusted by -0.2 s\n",
      "Saving videos in /adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos\n",
      "Trial 1, from 3486 to 3871, 385 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_1.avi\n",
      "Trial 2, from 4169 to 4597, 428 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_2.avi\n",
      "Trial 3, from 4896 to 5398, 502 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_3.avi\n",
      "Trial 4, from 6108 to 6383, 275 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_4.avi\n",
      "Trial 5, from 6680 to 6910, 230 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_5.avi\n",
      "Trial 6, from 7207 to 9107, 1900 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_6.avi\n",
      "Trial 7, from 9405 to 11537, 2132 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_7.avi\n",
      "Trial 8, from 12285 to 13038, 753 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_8.avi\n",
      "Trial 9, from 13334 to 16461, 3127 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_9.avi\n",
      "Trial 10, from 16757 to 18054, 1297 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_10.avi\n",
      "Trial 11, from 18353 to 23578, 5225 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_11.avi\n",
      "Trial 12, from 24230 to 24671, 441 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_12.avi\n",
      "Trial 13, from 24970 to 26835, 1865 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_13.avi\n",
      "Trial 14, from 27134 to 27360, 226 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_14.avi\n",
      "Trial 15, from 27659 to 28096, 437 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_15.avi\n",
      "Trial 16, from 28802 to 29029, 227 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_16.avi\n",
      "Trial 17, from 29329 to 30485, 1156 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_17.avi\n",
      "Trial 18, from 30776 to 31033, 257 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_18.avi\n",
      "Trial 19, from 31332 to 31804, 472 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_19.avi\n",
      "Trial 20, from 32456 to 32719, 263 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_20.avi\n",
      "Trial 21, from 33016 to 35148, 2132 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_21.avi\n",
      "Trial 22, from 35446 to 35695, 249 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_22.avi\n",
      "Trial 23, from 35992 to 37050, 1058 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_23.avi\n",
      "Trial 24, from 37842 to 38994, 1152 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_24.avi\n",
      "Trial 25, from 39291 to 39989, 698 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_25.avi\n",
      "Trial 26, from 40276 to 40530, 254 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_26.avi\n",
      "Trial 27, from 40830 to 41343, 513 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_27.avi\n",
      "Trial 28, from 42079 to 42318, 239 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_28.avi\n",
      "Trial 29, from 42615 to 43016, 401 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_29.avi\n",
      "Trial 30, from 43315 to 43936, 621 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_30.avi\n",
      "Trial 31, from 44235 to 45217, 982 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_31.avi\n",
      "Trial 32, from 46019 to 46495, 476 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_32.avi\n",
      "Trial 33, from 46795 to 53749, 6954 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_33.avi\n",
      "Trial 34, from 54039 to 54370, 331 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_34.avi\n",
      "Trial 35, from 54669 to 56798, 2129 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_35.avi\n",
      "Trial 36, from 57625 to 57871, 246 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_36.avi\n",
      "Trial 37, from 58169 to 58802, 633 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_37.avi\n",
      "Trial 38, from 59098 to 59335, 237 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_38.avi\n",
      "Trial 39, from 59633 to 59980, 347 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_39.avi\n",
      "Trial 40, from 60568 to 60983, 415 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_40.avi\n",
      "Trial 41, from 61282 to 62049, 767 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_41.avi\n",
      "Trial 42, from 62338 to 62557, 219 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_42.avi\n",
      "Trial 43, from 62856 to 63269, 413 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_43.avi\n",
      "Trial 44, from 63817 to 64004, 187 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_44.avi\n",
      "Trial 45, from 64303 to 64629, 326 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_45.avi\n",
      "Trial 46, from 64918 to 65178, 260 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_46.avi\n",
      "Trial 47, from 65472 to 66671, 1199 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_47.avi\n",
      "Trial 48, from 67444 to 67898, 454 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_48.avi\n",
      "Trial 49, from 68193 to 69511, 1318 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_49.avi\n",
      "Trial 50, from 69801 to 70056, 255 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_50.avi\n",
      "Trial 51, from 72181 to 73161, 980 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_51.avi\n",
      "Trial 52, from 73458 to 76837, 3379 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_52.avi\n",
      "Trial 53, from 77127 to 77552, 425 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_53.avi\n",
      "Trial 54, from 77850 to 78800, 950 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_54.avi\n",
      "Trial 55, from 79469 to 79713, 244 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_55.avi\n",
      "Trial 56, from 80721 to 80937, 216 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_56.avi\n",
      "Trial 57, from 81226 to 83149, 1923 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_57.avi\n",
      "Trial 58, from 83941 to 84324, 383 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_58.avi\n",
      "Trial 59, from 84621 to 85322, 701 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_59.avi\n",
      "Trial 60, from 85612 to 85839, 227 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_60.avi\n",
      "Trial 61, from 86138 to 87169, 1031 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_61.avi\n",
      "Trial 62, from 87793 to 88109, 316 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_62.avi\n",
      "Trial 63, from 88407 to 90386, 1979 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_63.avi\n",
      "Trial 64, from 90682 to 91498, 816 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_64.avi\n",
      "Trial 65, from 91797 to 93106, 1309 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_65.avi\n",
      "Trial 66, from 93815 to 94576, 761 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_66.avi\n",
      "Trial 67, from 94875 to 95327, 452 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_67.avi\n",
      "Trial 68, from 95615 to 95832, 217 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_68.avi\n",
      "Trial 69, from 96128 to 97063, 935 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_69.avi\n",
      "Trial 70, from 97646 to 97872, 226 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_70.avi\n",
      "Trial 71, from 98170 to 98779, 609 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_71.avi\n",
      "Trial 72, from 99068 to 99432, 364 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_72.avi\n",
      "Trial 73, from 99729 to 100145, 416 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_73.avi\n",
      "Trial 74, from 100828 to 102208, 1380 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_74.avi\n",
      "Trial 75, from 102506 to 103741, 1235 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_75.avi\n",
      "Trial 76, from 104041 to 104452, 411 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_76.avi\n",
      "Trial 77, from 104750 to 105837, 1087 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_77.avi\n",
      "Trial 78, from 106613 to 106844, 231 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_78.avi\n",
      "Trial 79, from 107134 to 108019, 885 frames\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_79.avi\n"
     ]
    }
   ],
   "source": [
    "ses = myProject.sessionList[0]\n",
    "ses.extractTrialFeatures()\n",
    "#ses.createTrialPlots()\n",
    "ses.createTrialVideos()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-lemon",
   "metadata": {},
   "source": [
    "From looking at the trial plots, I selected trial 38 (light) and trials 27, 31 (dark).\n",
    "\n",
    "We can probably paste them one after the other for a presentation. You can use ffmpeg for this\n",
    "\n",
    "Create a file called myList with this content:\n",
    "```\n",
    "file '/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_38.avi'\n",
    "file '/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_27.avi'\n",
    "file '/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/trialVideos/mn4656-30092019-2001.trial_31.avi'\n",
    "```\n",
    "\n",
    "Then run \n",
    "`ffmpeg -f concat -safe 0 -i myList  -c:v libx264 -crf 18   -c copy video_draft.avi`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-memorabilia",
   "metadata": {},
   "source": [
    "# Lever video\n",
    "\n",
    "I also created a video of the lever tracking and navigation.\n",
    "\n",
    "```\n",
    "vlc mn4656-30092019-2001.arena_top.cropped.avi\n",
    "```\n",
    "\n",
    "I found a segment I liked between 15:35-1601.\n",
    "\n",
    "```\n",
    "ffmpeg -ss 00:00:00 -i mn4656-30092019-2001.arena_top.avi -ss 00:15:36 -t 00:00:17 -c copy short.mp4\n",
    "```\n",
    "\n",
    "We can then use the LeverDetector class of autopipy to get a labeled video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "collectible-simulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n",
      "Removing previous inference data: /adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/shortDLC_resnet_50_leverDetectorSep29shuffle1_350000.h5\n",
      "Running dlc.analyze_video on /adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/short.mp4\n",
      "Using snapshot-350000 for model /adata/models/leverDetector-Allen-2020-09-29/dlc-models/iteration-0/leverDetectorSep29-trainset90shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/510 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/short.mp4\n",
      "/adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001  already exists!\n",
      "Loading  /adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/short.mp4\n",
      "Duration of video [s]:  17.0 , recorded with  30.0 fps!\n",
      "Overall # of frames:  510  found with (before cropping) frame dimensions:  640 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "520it [00:09, 56.01it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "dlc.loadPositionData() read data from /adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/shortDLC_resnet_50_leverDetectorSep29shuffle1_350000.h5\n",
      "dlc.loadPositionData() read data from /adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/shortDLC_resnet_50_leverDetectorSep29shuffle1_350000.h5\n",
      "Saving position data to /adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/shortDLC_resnet_50_leverDetectorSep29shuffle1_350000.csv\n",
      "dlc.loadPositionData() read data from /adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/shortDLC_resnet_50_leverDetectorSep29shuffle1_350000.h5\n",
      "Saving labeled video in /adata/projects/autopi_behavior_2021/mn4656/mn4656-30092019-2001/leverMvt.mp4\n"
     ]
    }
   ],
   "source": [
    "os.environ['DLClight'] = 'True'\n",
    "from autopipy.dlcObjectDetectors import LeverDetector\n",
    "importlib.reload(autopipy.dlcObjectDetectors)\n",
    "from autopipy.dlcObjectDetectors import LeverDetector\n",
    "\n",
    "leverDetectorModel = \"leverDetector-Allen-2020-09-29\"\n",
    "configFile=dlcModelPath + \"/\" + leverDetectorModel + \"/config.yaml\"\n",
    "configFile\n",
    "\n",
    "inputFile = ses.path + \"/short.mp4\"\n",
    "inputFile\n",
    "\n",
    "outputFile = ses.path + \"/leverMvt.mp4\"\n",
    "\n",
    "leverD = LeverDetector(pathConfigFile=configFile)\n",
    "leverD.inferenceVideo(pathVideoFile=inputFile,overwrite=True)\n",
    "leverD.labelVideoLever(pathVideoFile=inputFile,pathOutputFile=outputFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-stage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-plane",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
